## Description

AGR ANALYSIS is project in which  we are working on a customer transaction dataset by using Apache Spark, which is a data processing framework that can quickly perform
processing tasks on very large data sets, and can also distribute data processing tasks across multiple computers, either on its own or in tandem with other distributed computing
tools. Using these datasets and Spark SQL we have created various use cases pertaining to real life scenarios in banking.We have used azure databricks as an platform to work with 
our available data.We have used various services of azure databricks to get insights from the avialble dataset.In this project we have used azure devops services for continuous integration
and continuous delivery.

## STEPS TO RUN PROJECT
1.log in into  microsoft azure or azure databricks account. 

2.Create sparkSession using spark and load and read the csv file .

3.copy the code from code.txt from code folder and paste into the databricks platform.

4.press shift+ enter or run in databricks platform to run the code.

## TOOLS AND TECHNOLOGIES

1.SPARK
2.PYTHON
3.PYSPARK 
4.SPARK SQL 
5.MICROSOFT AZURE 
6.AZURE DEVOPS SERVICES
7.DATABRICKS
8.DATAFRAMES

## ROLES AND RESPONSIBILITY
1.WORKED WITH AZURE DEVOPS SERVICES FOR CONTINIOUS INTEGRATION AND CONTINIOUS DELIVERY.

2.WROTE YML SCRIPT FOR AUTOMATING  CONTINIOUS DELIVERY.

3.CREATED VIRTUAL MACHINES AND STORAGE ACCOUNT IN AZURE PLATFORM.

4.WORKED WITH AZURE DATABRICKS AND ITS VARIOUS COMPUTING SERVICES.

5.CREATED RESUABLE METHODS FOR GETTING INSIGHTS FROM THE DATASETS USING PYTHON.

### CONTRIBUTORS
1.ANAND KOYALMUDI  2.GANESH BODUGU  3.ROHIT SHREEYA

